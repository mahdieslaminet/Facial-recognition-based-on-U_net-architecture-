{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "25a8d8a7-d089-434e-93f7-a05808ed5117",
      "cell_type": "code",
      "source": "# NOTE: Due to hardware limitations (mobile) and large dataset size,\n# I could not upload the dataset here.\n# The code is complete and ready to run on a local machine.\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model\nimport datetime\n\ndef conv_block(inputs, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x\n\ndef encoder_block(inputs, num_filters):\n    x = conv_block(inputs, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p\n\ndef decoder_block(inputs, skip, num_filters):\n    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n    x = Concatenate()([x, skip])\n    x = conv_block(x, num_filters)\n    return x\n\n\ndef build_unet(INPUT_SHAPE):\n    inputs = Input(INPUT_SHAPE)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name='U-Net')\n    return model\n\ndef second_to_time(n):\n    return str(datetime.timedelta(seconds = n))\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cdd4b42f-83fa-42a7-884d-cbb374444fd7",
      "cell_type": "code",
      "source": "\nimport os\nimport cv2\nimport time\nimport numpy as np\nimport tensorflow as tf\nimport segmentation_models as sm\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n\nfrom unet import build_unet\nfrom glob import glob\n\nglobal IMAGE_HEIGHT\nglobal IMAGE_WIDTH\nglobal INPUT_SHAPE\nglobal EPOCHS_COUNT\nglobal new_directories\nglobal DATASET_PATH\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\nDATASET_PATH = \"dataset\\\\Thyroid Dataset\\\\tg3k\"\n\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nINPUT_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, 1)\nEPOCHS_COUNT = 10\n\nnew_directories = [\n        f'{DATASET_PATH}\\\\train\\\\images',\n        f'{DATASET_PATH}\\\\train\\\\labels',\n        f'{DATASET_PATH}\\\\val\\\\images',\n        f'{DATASET_PATH}\\\\val\\\\labels',\n        f'{DATASET_PATH}\\\\test\\\\images',\n        f'{DATASET_PATH}\\\\test\\\\labels'\n        ]\n\ndef read_image_mask(x, y, exapnd_it = False):\n    \"\"\" Image \"\"\"\n    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n    x = cv2.resize(x, (IMAGE_WIDTH, IMAGE_HEIGHT))\n    \n    \"\"\" Mask \"\"\"\n    y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    y = cv2.resize(y, (IMAGE_WIDTH, IMAGE_HEIGHT))\n\n    if exapnd_it:\n        x = x/255.0\n        x = x.astype(np.float32)\n\n        y = y/255.0\n        y = y.astype(np.float32)\n\n        x = np.expand_dims(x, axis=-1) # 256 X 256 X 1\n        y = np.expand_dims(y, axis=-1)\n    \n    return x, y\n\ndef _image_to_tensor(func, x, y):\n    image, mask = tf.numpy_function(func, [x, y], [tf.float32, tf.float32])\n     \n    image.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n    mask.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n\n    return image, mask\n\ndef preprocess(x, y):\n    def f(x, y):\n        x = x.decode()\n        y = y.decode()\n        return read_image_mask(x, y, True)\n\n    image, mask = _image_to_tensor(f, x, y)\n\n    return image, mask\n\ndef tf_dataset(X, Y, batch=8):\n    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n    ds = ds.shuffle(buffer_size=5000).map(preprocess) \n    ds = ds.batch(batch).prefetch(2)\n    return ds\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef load_dataset(path):\n\n    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.jpg\")))\n    train_y = sorted(glob(os.path.join(path, \"train\", \"labels\", \"*.jpg\")))\n\n    valid_x = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.jpg\")))\n    valid_y = sorted(glob(os.path.join(path, \"val\", \"labels\", \"*.jpg\")))\n\n    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.jpg\")))\n    test_y = sorted(glob(os.path.join(path, \"test\", \"labels\", \"*.jpg\")))\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n\ndef change_dataset():\n    import json\n\n    for new_directory in new_directories:\n        create_dir(new_directory)\n\n    with open(f'{DATASET_PATH}\\\\tg3k-trainval.json') as f:\n        data = json.load(f)\n        for i, file_info in enumerate(data['val']):\n            file_name = f'{file_info}.jpg'\n            img_path = f'{new_directories[0]}\\\\{file_name}'\n            mask_path = f'{new_directories[1]}\\\\{file_name}'\n\n            if i % 7 == 0:\n                os.rename(img_path, f\"{new_directories[2]}\\\\{file_name}\")\n                os.rename(mask_path, f\"{new_directories[3]}\\\\{file_name}\")\n            else:\n                os.rename(img_path, f\"{new_directories[4]}\\\\{file_name}\")\n                os.rename(mask_path, f\"{new_directories[5]}\\\\{file_name}\")\n\n\ndef train():\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Loading the dataset \"\"\"\n    (train_x, train_y), (valid_x, valid_y), (_, _) = load_dataset(DATASET_PATH)\n\n    \"\"\" Dataset Pipeline \"\"\"\n    train_ds = tf_dataset(train_x, train_y)\n    valid_ds = tf_dataset(valid_x, valid_y)\n\n    \"\"\" Directory for storing files \"\"\"\n    create_dir(\"files\")\n    model_name = 'UNet'\n    model_info = f'{model_name}_{len(train_x)}imgs_{EPOCHS_COUNT}epochs11'\n    model_path = os.path.join(\"files\", f\"model_{model_info}.h5\")\n    csv_path = os.path.join(\"files\", f\"data_{model_info}.csv\")\n\n    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)}\")\n    print(\"\")\n\n    \"\"\" Model \"\"\"\n    unet_model = build_unet(INPUT_SHAPE)\n\n    unet_model.compile(\n        loss=[sm.losses.binary_crossentropy],\n        metrics=[sm.metrics.iou_score],\n        optimizer=tf.keras.optimizers.Adam(1e-4)\n    )\n\n    \"\"\" Training \"\"\"\n    callbacks = [\n            ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=1e-7, verbose=1),\n            CSVLogger(csv_path, append=True),\n            EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=False)\n            ]\n\n    start_time = time.time()\n    unet_model.fit(train_ds,\n                   validation_data=valid_ds,\n                   epochs=EPOCHS_COUNT,\n                   callbacks=callbacks)\n\n\n# Test\n\ndef test():\n    import os\n    import numpy as np\n    import tensorflow as tf\n    \n    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\n    \"\"\" Seeding \"\"\"\n    np.random.seed(42)\n    tf.random.set_seed(42)\n\n    \"\"\" Hyperparameters \"\"\"\n\n    \"\"\" Paths \"\"\"\n    model_name = 'model_UNet_3226imgs_10epochs.h5'\n    model_path = os.path.join(\"files\", model_name)\n\n    \"\"\" Directory for storing files \"\"\"\n    dirc_name = f'{model_name}_results'\n    create_dir(dirc_name)\n\n    \"\"\" Loading the dataset \"\"\"\n    (_, _), (_, _), (test_x, test_y) = load_dataset(DATASET_PATH)\n\n    print(f\"Test: {len(test_x)}/{len(test_x)}\")\n    print(\"\")\n\n    \"\"\" Load the model \"\"\"\n    model = tf.keras.models.load_model(model_path, compile=False)\n\n    \"\"\" Prediction & Evaluation \"\"\"\n    i = 0\n    for x, y in zip(test_x, test_y):\n        print(i)\n        i += 1\n        \"\"\" Extract the name \"\"\"\n        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n\n        \"\"\" Reading the image and mask\"\"\"\n        image, mask = read_image_mask(x, y)\n        h, w = image.shape\n        image_x = image.copy()\n        image = image/255.0\n        image = image.astype(np.float32)\n        image = np.expand_dims(image, axis=0) ## [1, H, W]\n\n        \"\"\" Prediction \"\"\"\n        pred = model.predict(image, verbose=0)[0]\n\n        pred = (pred > 0.5) * 255\n        pred = pred.astype(np.int32)\n        pred = cv2.resize(pred, (w, h))\n\n        line = np.ones((image_x.shape[0], 10)) * 255\n\n        image_x = image_x.astype(np.int32)\n        pred = pred.astype(np.int32)\n\n        cat_images = np.concatenate([image_x, line, mask, line, pred], axis=1)\n        cv2.imwrite(f'{dirc_name}//{name}.jpg', cat_images)\n\ntest()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}